{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transfomer based models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "205ugscls4ji"
      },
      "source": [
        "If using google colab run below cell and restart runtime. (Remember to use GPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLMDZFr2s1sC",
        "outputId": "26274627-5743-4aa4-be3a-1084b4c71ac3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxygC3uHEm6H",
        "outputId": "54a1261f-5602-4b6a-ba5c-a1d9dedaf2e3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install update transformers\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lnWKBhx4Eqde"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "from datasets import load_metric\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForQuestionAnswering\n",
        "from transformers import AutoConfig\n",
        "from functools import partial\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "from torch import nn\n",
        "from collections import defaultdict, OrderedDict\n",
        "from datasets import DatasetDict\n",
        "#MODEL_NAME = 'xlm-roberta-base'\n",
        "#MODEL_NAME = 'bert-base-uncased'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qss0FaeJEr51"
      },
      "outputs": [],
      "source": [
        "def enforce_reproducibility(seed=42):\n",
        "    # Sets seed manually for both CPU and CUDA\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    # For atomic operations there is currently\n",
        "    # no simple way to enforce determinism, as\n",
        "    # the order of parallel operations is not known.\n",
        "    # CUDNN\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    # System based\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "\n",
        "enforce_reproducibility()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hls4p8dME_B4"
      },
      "source": [
        "## Loading and preparing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whxrl_kfFD-6",
        "outputId": "21386331-7642-4650-c4bb-900d6b58e90e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adding  indonesian to dict\n",
            "Adding  bengali to dict\n",
            "Adding  arabic to dict\n"
          ]
        }
      ],
      "source": [
        "dataset = load_dataset(\"copenlu/answerable_tydiqa\")\n",
        "train_set = dataset[\"train\"]\n",
        "validation_set = dataset[\"validation\"]\n",
        "\n",
        "languages = ['indonesian', 'bengali', 'arabic']\n",
        "\n",
        "# Creating a dictionary for the training and validation set, that holds all three languages.\n",
        "train_set_dict = {}\n",
        "val_set_dict = {}\n",
        "\n",
        "for language in languages:\n",
        "    print(\"Adding \", language, \"to dict\")\n",
        "    train_set_dict[language] = train_set.filter(lambda example: example[\"language\"] == language)\n",
        "    val_set_dict[language] = validation_set.filter(lambda example: example[\"language\"] == language)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "foVFldpdFgk5"
      },
      "outputs": [],
      "source": [
        "# Making sure that our dataset has the same shape as SquAD_V2\n",
        "\n",
        "def reformat_example(example, idx):\n",
        "    example[\"id\"] = str(idx)\n",
        "\n",
        "    # Rename columns\n",
        "    example[\"title\"] = example.pop(\"document_title\")\n",
        "    example[\"context\"] = example.pop(\"document_plaintext\")\n",
        "    example[\"question\"] = example.pop(\"question_text\")\n",
        "\n",
        "    # Reformat the answers structure\n",
        "    annotations = example.pop(\"annotations\")\n",
        "    example[\"answers\"] = {\n",
        "        \"text\": annotations[\"answer_text\"],\n",
        "        \"answer_start\": annotations[\"answer_start\"]\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "    return example\n",
        "\n",
        "TEST_SIZE = 0.15\n",
        "\n",
        "def training_split(train_dict, val_dict):\n",
        "    dict_list = DatasetDict()\n",
        "\n",
        "    for key in train_dict.keys():\n",
        "        hugging_dict = DatasetDict()\n",
        "\n",
        "        # Transform the train dataset\n",
        "        hugging_dict['train'] = train_dict[key].select_columns(['question_text', 'document_title', 'document_plaintext', 'annotations'])\n",
        "        hugging_dict['train'] = hugging_dict['train'].map(reformat_example, with_indices=True)\n",
        "\n",
        "        # Transform the validation dataset\n",
        "        hugging_dict['validation'] = val_dict[key].select_columns(['question_text', 'document_title', 'document_plaintext', 'annotations'])\n",
        "        hugging_dict['validation'] = hugging_dict['validation'].map(reformat_example, with_indices=True)\n",
        "\n",
        "        dict_list[key] = hugging_dict\n",
        "\n",
        "    return dict_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xoXpQ6tZF_6_"
      },
      "outputs": [],
      "source": [
        "tydiqa = training_split(train_set_dict, val_set_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zO58zsIdKEPh",
        "outputId": "f52341a2-981c-49cd-e5df-1af94244fc80"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-b9750ac7b5bc>:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  compute_squad = load_metric(\"squad_v2\")\n"
          ]
        }
      ],
      "source": [
        "compute_squad = load_metric(\"squad_v2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvxjROJLJBY8"
      },
      "source": [
        "## Multilingual Bert model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Shared function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FLuywBfTKDNS"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"bert-base-multilingual-cased\"\n",
        "#MODEL_NAME = \"indolem/indobert-base-uncased\"\n",
        "tk = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MD4VlEyWHEyd"
      },
      "outputs": [],
      "source": [
        "def get_train_features(tk, samples):\n",
        "  '''\n",
        "  Tokenizes all of the text in the given samples, splittling inputs that are too long for our model\n",
        "  across multiple features. Finds the token offsets of the answers, which serve as the labels for\n",
        "  our inputs.\n",
        "  '''\n",
        "  batch = tk.batch_encode_plus(\n",
        "        [[q,c] for q,c in zip(samples['question'], samples['context'])],\n",
        "        padding='max_length',\n",
        "         max_length=512,\n",
        "        truncation='only_second',\n",
        "        stride=128,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True\n",
        "    )\n",
        "\n",
        "  # Get a list which maps the input features index to their original index in the\n",
        "  # samples list (for split inputs). E.g. if our batch size is 4 and the second sample\n",
        "  # is split into 3 inputs because it is very large, sample_mapping would look like\n",
        "  # [0, 1, 1, 1, 2, 3]\n",
        "  sample_mapping = batch.pop('overflow_to_sample_mapping')\n",
        "  # Get all of the character offsets for each token\n",
        "  offset_mapping = batch.pop('offset_mapping')\n",
        "\n",
        "  # Store the start and end tokens\n",
        "  batch['start_tokens'] = []\n",
        "  batch['end_tokens'] = []\n",
        "\n",
        "  # Iterate through all of the offsets\n",
        "  for i, offsets in enumerate(offset_mapping):\n",
        "    # Get the right sample by mapping it to its original index\n",
        "    sample_idx = sample_mapping[i]\n",
        "    # Get the sequence IDs to know where context starts so we can ignore question tokens\n",
        "    sequence_ids = batch.sequence_ids(i)\n",
        "\n",
        "    # Get the start and end character positions of the answer\n",
        "    ans = samples['answers'][sample_idx]\n",
        "    start_char = ans['answer_start'][0]\n",
        "    end_char = start_char + len(ans['text'][0])\n",
        "    # while end_char > 0 and (end_char >= len(samples['context'][sample_idx]) or samples['context'][sample_idx][end_char] == ' '):\n",
        "    #   end_char -= 1\n",
        "\n",
        "    # Start from the first token in the context, which can be found by going to the\n",
        "    # first token where sequence_ids is 1\n",
        "    start_token = 0\n",
        "    while sequence_ids[start_token] != 1:\n",
        "      start_token += 1\n",
        "\n",
        "    end_token = len(offsets) - 1\n",
        "    while sequence_ids[end_token] != 1:\n",
        "      end_token -= 1\n",
        "\n",
        "    # By default set it to the CLS token if the answer isn't in this input\n",
        "    if start_char < offsets[start_token][0] or end_char > offsets[end_token][1]:\n",
        "      start_token = 0\n",
        "      end_token = 0\n",
        "    # Otherwise find the correct token indices\n",
        "    else:\n",
        "      # Advance the start token index until we have passed the start character index\n",
        "      while start_token < len(offsets) and offsets[start_token][0] <= start_char:\n",
        "        start_token += 1\n",
        "      start_token -= 1\n",
        "\n",
        "      # Decrease the end token index until we have passed the end character index\n",
        "      while end_token >= 0 and offsets[end_token][1] >= end_char:\n",
        "        end_token -= 1\n",
        "      end_token += 1\n",
        "\n",
        "    batch['start_tokens'].append(start_token)\n",
        "    batch['end_tokens'].append(end_token)\n",
        "\n",
        "  #batch['start_tokens'] = np.array(batch['start_tokens'])\n",
        "  #batch['end_tokens'] = np.array(batch['end_tokens'])\n",
        "\n",
        "  return batch\n",
        "\n",
        "def collate_fn(inputs):\n",
        "  '''\n",
        "  Defines how to combine different samples in a batch\n",
        "  '''\n",
        "  input_ids = torch.tensor([i['input_ids'] for i in inputs])\n",
        "  attention_mask = torch.tensor([i['attention_mask'] for i in inputs])\n",
        "  start_tokens = torch.tensor([i['start_tokens'] for i in inputs])\n",
        "  end_tokens = torch.tensor([i['end_tokens'] for i in inputs])\n",
        "\n",
        "  # Truncate to max length\n",
        "  max_len = max(attention_mask.sum(-1))\n",
        "  input_ids = input_ids[:,:max_len]\n",
        "  attention_mask = attention_mask[:,:max_len]\n",
        "\n",
        "  return {'input_ids': input_ids, 'attention_mask': attention_mask, 'start_tokens': start_tokens, 'end_tokens': end_tokens}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kE5sI3omQkx6"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    model: nn.Module,\n",
        "    train_dl: DataLoader,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    schedule: LambdaLR,\n",
        "    n_epochs: int,\n",
        "    device: torch.device\n",
        "):\n",
        "  \"\"\"\n",
        "  The main training loop which will optimize a given model on a given dataset\n",
        "  :param model: The model being optimized\n",
        "  :param train_dl: The training dataset\n",
        "  :param optimizer: The optimizer used to update the model parameters\n",
        "  :param n_epochs: Number of epochs to train for\n",
        "  :param device: The device to train on\n",
        "  \"\"\"\n",
        "\n",
        "  # Keep track of the loss and best accuracy\n",
        "  losses = []\n",
        "  best_acc = 0.0\n",
        "  pcounter = 0\n",
        "\n",
        "  # Iterate through epochs\n",
        "  for ep in range(n_epochs):\n",
        "\n",
        "    loss_epoch = []\n",
        "\n",
        "    #Iterate through each batch in the dataloader\n",
        "    for batch in tqdm(train_dl):\n",
        "      # VERY IMPORTANT: Make sure the model is in training mode, which turns on\n",
        "      # things like dropout and layer normalization\n",
        "      model.train()\n",
        "\n",
        "      # VERY IMPORTANT: zero out all of the gradients on each iteration -- PyTorch\n",
        "      # keeps track of these dynamically in its computation graph so you need to explicitly\n",
        "      # zero them out\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Place each tensor on the GPU\n",
        "      batch = {b: batch[b].to(device) for b in batch}\n",
        "\n",
        "      # Pass the inputs through the model, get the current loss and logits\n",
        "      outputs = model(\n",
        "          input_ids=batch['input_ids'],\n",
        "          attention_mask=batch['attention_mask'],\n",
        "          start_positions=batch['start_tokens'],\n",
        "          end_positions=batch['end_tokens']\n",
        "      )\n",
        "      loss = outputs['loss']\n",
        "      losses.append(loss.item())\n",
        "      loss_epoch.append(loss.item())\n",
        "\n",
        "      # Calculate all of the gradients and weight updates for the model\n",
        "      loss.backward()\n",
        "\n",
        "      # Optional: clip gradients\n",
        "      #torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "      # Finally, update the weights of the model and advance the LR schedule\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "      #gc.collect()\n",
        "  return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5aw-8JvbQoeJ"
      },
      "outputs": [],
      "source": [
        "def get_validation_features(tk, samples):\n",
        "  # First, tokenize the text. We get the offsets and return overflowing sequences in\n",
        "  # order to break up long sequences into multiple inputs. The offsets will help us\n",
        "  # determine the original answer text\n",
        "  batch = tk.batch_encode_plus(\n",
        "        [[q,c] for q,c in zip(samples['question'], samples['context'])],\n",
        "        padding='max_length',\n",
        "        max_length = 512,\n",
        "        truncation='only_second',\n",
        "        stride=128,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True\n",
        "    )\n",
        "\n",
        "  # We'll store the ID of the samples to calculate squad score\n",
        "  batch['example_id'] = []\n",
        "  # The overflow sample map tells us which input each sample corresponds to\n",
        "  sample_map = batch.pop('overflow_to_sample_mapping')\n",
        "\n",
        "  for i in range(len(batch['input_ids'])):\n",
        "    # The sample index tells us which of the values in \"samples\" these features belong to\n",
        "    sample_idx = sample_map[i]\n",
        "    sequence_ids = batch.sequence_ids(i)\n",
        "\n",
        "    # Add the ID to map these features back to the correct sample\n",
        "    batch['example_id'].append(samples['id'][sample_idx])\n",
        "\n",
        "    #Set offsets for non-context words to be None for ease of processing\n",
        "    batch['offset_mapping'][i] = [o if sequence_ids[k] == 1 else None for k,o in enumerate(batch['offset_mapping'][i])]\n",
        "\n",
        "  return batch\n",
        "\n",
        "def val_collate_fn(inputs):\n",
        "  input_ids = torch.tensor([i['input_ids'] for i in inputs])\n",
        "  attention_mask = torch.tensor([i['attention_mask'] for i in inputs])\n",
        "\n",
        "  # Truncate to max length\n",
        "  max_len = max(attention_mask.sum(-1))\n",
        "  input_ids = input_ids[:,:max_len]\n",
        "  attention_mask = attention_mask[:,:max_len]\n",
        "\n",
        "  return {'input_ids': input_ids, 'attention_mask': attention_mask}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "q8bYq9WhQurg"
      },
      "outputs": [],
      "source": [
        "def predict(model: nn.Module, valid_dl: DataLoader):\n",
        "  \"\"\"\n",
        "  Evaluates the model on the given dataset\n",
        "  :param model: The model under evaluation\n",
        "  :param valid_dl: A `DataLoader` reading validation data\n",
        "  :return: The accuracy of the model on the dataset\n",
        "  \"\"\"\n",
        "  # VERY IMPORTANT: Put your model in \"eval\" mode -- this disables things like\n",
        "  # layer normalization and dropout\n",
        "  model.eval()\n",
        "  start_logits_all = []\n",
        "  end_logits_all = []\n",
        "\n",
        "  # ALSO IMPORTANT: Don't accumulate gradients during this process\n",
        "  with torch.no_grad():\n",
        "    for batch in tqdm(valid_dl, desc='Evaluation'):\n",
        "      batch = {b: batch[b].to(device) for b in batch}\n",
        "\n",
        "      # Pass the inputs through the model, get the current loss and logits\n",
        "      outputs = model(\n",
        "          input_ids=batch['input_ids'],\n",
        "          attention_mask=batch['attention_mask']\n",
        "      )\n",
        "      # Store the \"start\" class logits and \"end\" class logits for every token in the input\n",
        "      start_logits_all.extend(list(outputs['start_logits'].detach().cpu().numpy()))\n",
        "      end_logits_all.extend(list(outputs['end_logits'].detach().cpu().numpy()))\n",
        "\n",
        "\n",
        "    return start_logits_all,end_logits_all\n",
        "\n",
        "def post_process_predictions(examples, dataset, logits, num_possible_answers = 20, max_answer_length = 30):\n",
        "  all_start_logits, all_end_logits = logits\n",
        "  # Build a map from example to its corresponding features. This will allow us to index from\n",
        "  # sample ID to all of the features for that sample (in case they were split up due to long input)\n",
        "  example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
        "  features_per_example = defaultdict(list)\n",
        "  for i, feature in enumerate(dataset):\n",
        "      features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
        "\n",
        "  # Create somewhere to store our predictions\n",
        "  predictions = OrderedDict()\n",
        "\n",
        "  # Iterate through each sample in the dataset\n",
        "  for j, sample in enumerate(tqdm(examples)):\n",
        "\n",
        "    # Get the feature indices (all of the features split across the batch)\n",
        "    feature_indices = features_per_example[j]\n",
        "    # Get the original context which predumably has the answer text\n",
        "    context = sample['context']\n",
        "\n",
        "    preds = []\n",
        "    # Iterate through all of the features\n",
        "    for ft_idx in feature_indices:\n",
        "\n",
        "      # Get the start and end answer logits for this input\n",
        "      start_logits = all_start_logits[ft_idx]\n",
        "      end_logits = all_end_logits[ft_idx]\n",
        "\n",
        "      # Get the offsets to map token indices to character indices\n",
        "      offset_mapping = dataset[ft_idx]['offset_mapping']\n",
        "\n",
        "      # Sort the logits and take the top N\n",
        "      start_indices = np.argsort(start_logits)[::-1][:num_possible_answers]\n",
        "      end_indices = np.argsort(end_logits)[::-1][:num_possible_answers]\n",
        "\n",
        "      # Iterate through start and end indices\n",
        "      for start_index in start_indices:\n",
        "        for end_index in end_indices:\n",
        "\n",
        "          # Ignore this combination if either the indices are not in the context\n",
        "          if start_index >= len(offset_mapping) or end_index >= len(offset_mapping) or offset_mapping[start_index] is None or offset_mapping[end_index] is None:\n",
        "            continue\n",
        "\n",
        "          # Also ignore if the start index is greater than the end index of the number of tokens\n",
        "          # is greater than some specified threshold\n",
        "          if start_index > end_index or end_index - start_index + 1 > max_answer_length:\n",
        "            continue\n",
        "\n",
        "          ans_text = context[offset_mapping[start_index][0]:offset_mapping[end_index][1]]\n",
        "          preds.append({\n",
        "              'score': start_logits[start_index] + end_logits[end_index],\n",
        "              'text': ans_text\n",
        "          })\n",
        "\n",
        "    if len(preds) > 0:\n",
        "      # Sort by score to get the top answer\n",
        "      answer = sorted(preds, key=lambda x: x['score'], reverse=True)[0]\n",
        "    else:\n",
        "      answer = {'score': 0.0, 'text': \"\"}\n",
        "\n",
        "    predictions[sample['id']] = answer['text']\n",
        "  return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlqCaOIsLFSR"
      },
      "source": [
        "### Indonesian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2Y9cgU6K-K_N"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "\n",
        "enforce_reproducibility()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Dj3Z2kkLJw5Y"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset_indonesian = tydiqa['indonesian']['train'].map(partial(get_train_features, tk), batched=True, remove_columns=tydiqa['indonesian']['train'].column_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1AhAg-UTpmLD"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset_indonesian = tokenized_dataset_indonesian.train_test_split(test_size = 0.2)['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vXMHBEJoODvO"
      },
      "outputs": [],
      "source": [
        "#samples_indonesian = random.sample(list(range(len(tokenized_dataset_indonesian))), 4000)\n",
        "#tokenized_dataset_indonesian = tokenized_dataset_indonesian.select(samples_indonesian)\n",
        "train_dl_indonesian = DataLoader(tokenized_dataset_indonesian, collate_fn=collate_fn, shuffle=True, batch_size=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBdGYuCKL-lG",
        "outputId": "537939c6-0dce-4bfc-df38-e40366c7f0df"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model_indonesian = AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SlQLLu6iMC9X"
      },
      "outputs": [],
      "source": [
        "# Create the optimizer\n",
        "lr=2e-5\n",
        "n_epochs = 5\n",
        "weight_decay = 0.01\n",
        "warmup_steps = 200\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model_indonesian.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "      'weight_decay': weight_decay},\n",
        "    {'params': [p for n, p in model_indonesian.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=lr)\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    warmup_steps,\n",
        "    n_epochs * len(train_dl_indonesian)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SAmgg06IjD3",
        "outputId": "b91d7f50-bec4-4aae-cd3b-2c19cbe3d7d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7872800f9ae0>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dl_indonesian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHsunLQyNy-Y",
        "outputId": "2fb8bfd5-050e-4758-9283-3bc98ee8e83c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2323/2323 [03:08<00:00, 12.30it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2323/2323 [03:03<00:00, 12.69it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2323/2323 [03:02<00:00, 12.71it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2323/2323 [03:03<00:00, 12.66it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2323/2323 [03:04<00:00, 12.59it/s]\n"
          ]
        }
      ],
      "source": [
        "losses = train(\n",
        "    model_indonesian,\n",
        "    train_dl_indonesian,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    n_epochs,\n",
        "    device\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d73c44e9546347cbb514e277bc1b4a2c",
            "21ca25d58f544ba69b9b497e23cd36f6",
            "691663e8d179451f9c6f748668ac6214",
            "7ed960596ef04e4b90989c440d9971f1",
            "f94aec55f65e47969b595f8b59e79d20",
            "40e9bdb37e4440d98b7f3ff3cb8a158b",
            "3be1847ede7444a490bdde78ab67e258",
            "9b555d9a5919431f961e5e37f49ee9e8",
            "4deeaaa2a58845c795fdd5b536f8f9ca",
            "86a9059734a44d1bad58df3a6e829965",
            "4a9f5272d338449c8b358ed9789c35ed"
          ]
        },
        "id": "25fwr7WSPejd",
        "outputId": "58ec35a4-9f32-4035-d092-dcef32a3a273"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d73c44e9546347cbb514e277bc1b4a2c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1191 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "validation_dataset_indonesian = tydiqa['indonesian']['validation'].map(partial(get_validation_features, tk), batched=True, remove_columns=tydiqa['indonesian']['train'].column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-j7jsQ4TQWbu",
        "outputId": "20ff7485-c015-4474-c7e0-4f09bdb9bde3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:10<00:00,  3.54it/s]\n"
          ]
        }
      ],
      "source": [
        "val_dl_indonesian = DataLoader(validation_dataset_indonesian, collate_fn=val_collate_fn, batch_size=32)\n",
        "logits_indonesian = predict(model_indonesian, val_dl_indonesian)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9LPwR4VQbar",
        "outputId": "9f5b0b9e-67a0-4619-9f3d-e91bd1668d4e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1191/1191 [00:04<00:00, 266.21it/s]\n"
          ]
        }
      ],
      "source": [
        "predictions_indonesian = post_process_predictions(tydiqa['indonesian']['validation'], validation_dataset_indonesian, logits_indonesian)\n",
        "formatted_predictions_indonesian = [{'id': k, 'prediction_text': v, 'no_answer_probability': 0.5} for k,v in predictions_indonesian.items()]\n",
        "references_indonesian = [{'answers': example['answers'], 'id' : example['id']} for example in tydiqa['indonesian']['validation']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvsqWdncQkom",
        "outputId": "a7b18fa4-3b09-467c-a9c6-c44e4fe5e631"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'exact': 35.012594458438286,\n",
              " 'f1': 41.56794422215618,\n",
              " 'total': 1191,\n",
              " 'HasAns_exact': 35.012594458438286,\n",
              " 'HasAns_f1': 41.56794422215618,\n",
              " 'HasAns_total': 1191,\n",
              " 'best_exact': 35.012594458438286,\n",
              " 'best_exact_thresh': 0.5,\n",
              " 'best_f1': 41.56794422215618,\n",
              " 'best_f1_thresh': 0.5}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compute_squad.compute(predictions=formatted_predictions_indonesian, references = references_indonesian)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQ2NOgh5iGjL"
      },
      "source": [
        "### Bengali"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sakRR5OB-MV8"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "\n",
        "enforce_reproducibility()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5zb4kpLiJf0"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset_bengali = tydiqa['bengali']['train'].map(partial(get_train_features, tk), batched=True, remove_columns=tydiqa['bengali']['train'].column_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVewuBlMisJC",
        "outputId": "532bd7d4-725a-47a3-b9d6-a97aa6b77191"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "bengali_model = AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WO69X47jVwY"
      },
      "outputs": [],
      "source": [
        "#samples_bengali = random.sample(list(range(len(tokenized_dataset_bengali))), 4000)\n",
        "#tokenized_dataset_bengali = tokenized_dataset_bengali.select(samples_bengali)\n",
        "train_dl_bengali = DataLoader(tokenized_dataset_bengali, collate_fn=collate_fn, shuffle=True, batch_size=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6rPS4d3jZse",
        "outputId": "d6cd469a-1486-41a7-a6a4-1d388842d4b3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1300/1300 [02:23<00:00,  9.04it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1300/1300 [02:21<00:00,  9.21it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1300/1300 [02:21<00:00,  9.20it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1300/1300 [02:21<00:00,  9.16it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1300/1300 [02:20<00:00,  9.27it/s]\n"
          ]
        }
      ],
      "source": [
        "# Create the optimizer\n",
        "lr=2e-5\n",
        "n_epochs = 4\n",
        "weight_decay = 0.01\n",
        "warmup_steps = 200\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in bengali_model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "      'weight_decay': weight_decay},\n",
        "    {'params': [p for n, p in bengali_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "# optimizer = Adam(optimizer_grouped_parameters, lr=1e-3)\n",
        "# scheduler = None\n",
        "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=lr)\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    warmup_steps,\n",
        "    n_epochs * len(train_dl_bengali)\n",
        ")\n",
        "\n",
        "losses = train(\n",
        "    bengali_model,\n",
        "    train_dl_bengali,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    n_epochs,\n",
        "    device\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a9ae279af8964aabad8f410af59ae1c4",
            "5bf79c9c59cf46fca42266812ac3baf6",
            "d49e4b566fb6492aba84077af03878c0",
            "1e683f1484ac4be38cba81c2c4e23b6f",
            "e089df67654149bba79661a8c285f7c6",
            "b7967180a5224349ac7b1912adf60fd1",
            "7e5a1047764548d18c8c2bc9e42100e2",
            "326010bfd86a42c78cb774de6c343d91",
            "c423c8bfaf5f42ddaa11c6f4cbc47771",
            "4b8674dc5af04e30bdc5a435ead04a8c",
            "c9702701430b4ef699d4ff58f4c8747f"
          ]
        },
        "id": "suRordSplOTV",
        "outputId": "0bddea77-7d7a-46fb-a5cf-b48adb80978a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9ae279af8964aabad8f410af59ae1c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/224 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "validation_dataset_beng = tydiqa['bengali']['validation'].map(partial(get_validation_features, tk), batched=True, remove_columns=tydiqa['bengali']['train'].column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_-cLYlylugw"
      },
      "outputs": [],
      "source": [
        "val_beng_dl = DataLoader(validation_dataset_beng, collate_fn=val_collate_fn, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMmyf-LOjhaG",
        "outputId": "43147bf2-305d-4577-a5d4-ad4994445566"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:02<00:00,  3.07it/s]\n"
          ]
        }
      ],
      "source": [
        "logits_beng = predict(bengali_model, val_beng_dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ4OCwGOjkeY",
        "outputId": "a766cc3f-5dee-4133-8f9f-28580625c85e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<00:00, 228.09it/s]\n"
          ]
        }
      ],
      "source": [
        "predictions_beng = post_process_predictions(tydiqa['bengali']['validation'], validation_dataset_beng, logits_beng)\n",
        "formatted_predictions_beng = [{'id': k, 'prediction_text': v, 'no_answer_probability': 0.5} for k,v in predictions_beng.items()]\n",
        "references_beng = [{'answers': example['answers'], 'id' : example['id']} for example in tydiqa['bengali']['validation']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyvuYrOhmDGu",
        "outputId": "b392a1be-a624-4030-a5e1-73dc69b7d22f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'exact': 25.446428571428573,\n",
              " 'f1': 32.11850649350648,\n",
              " 'total': 224,\n",
              " 'HasAns_exact': 25.446428571428573,\n",
              " 'HasAns_f1': 32.11850649350648,\n",
              " 'HasAns_total': 224,\n",
              " 'best_exact': 25.446428571428573,\n",
              " 'best_exact_thresh': 0.5,\n",
              " 'best_f1': 32.11850649350648,\n",
              " 'best_f1_thresh': 0.5}"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compute_squad.compute(predictions=formatted_predictions_beng, references = references_beng)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3CZ9LBDzp-e"
      },
      "source": [
        "### Arabic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jGoL5wq-NnT"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "\n",
        "enforce_reproducibility()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3cD_FQpzrUL"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset_arabic = tydiqa['arabic']['train'].map(partial(get_train_features, tk), batched=True, remove_columns=tydiqa['arabic']['train'].column_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjpTXlY9z0eL",
        "outputId": "4f836af0-85eb-48af-f3cb-9716e430a3a3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "arabic_model = AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzR-bxTbz6SD"
      },
      "outputs": [],
      "source": [
        "#samples = random.sample(list(range(len(tokenized_dataset_arab))), 4000)\n",
        "#tokenized_dataset_arabic = tokenized_dataset_arab.select(samples)\n",
        "train_dl_arabic = DataLoader(tokenized_dataset_arabic, collate_fn=collate_fn, shuffle=True, batch_size=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBUEYavV0H0l",
        "outputId": "5e3d5421-5c00-4de2-a403-8112a9bab534"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7797/7797 [12:16<00:00, 10.58it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7797/7797 [12:15<00:00, 10.61it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7797/7797 [12:15<00:00, 10.60it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7797/7797 [12:17<00:00, 10.58it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7797/7797 [12:12<00:00, 10.64it/s]\n"
          ]
        }
      ],
      "source": [
        "# Create the optimizer\n",
        "lr=2e-5\n",
        "n_epochs = 4\n",
        "weight_decay = 0.01\n",
        "warmup_steps = 200\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in arabic_model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "      'weight_decay': weight_decay},\n",
        "    {'params': [p for n, p in arabic_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "# optimizer = Adam(optimizer_grouped_parameters, lr=1e-3)\n",
        "# scheduler = None\n",
        "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=lr)\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    warmup_steps,\n",
        "    n_epochs * len(train_dl_arabic)\n",
        ")\n",
        "\n",
        "losses = train(\n",
        "    arabic_model,\n",
        "    train_dl_arabic,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    n_epochs,\n",
        "    device\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "ed65d42325ca4a7785436c0ad75d5f78",
            "13a71ed997494a8296aa11f42d9e1589",
            "c39528ec1f854f63934a2768149ce72b",
            "65aef3f0c7e24db39ccd6a22536961fb",
            "eee0e5e47ce6417eaf40144976ad27b0",
            "6f2666fd7a8849c4a5e91cd68a7129cf",
            "72eb2b422b37492381bacffeec97b1ee",
            "97b9f3adfd734d26899c019fd726fc40",
            "19ce64d01e494d6b8a9579bdb2342bb2",
            "03490e623a7445e29836b8c045286ce5",
            "8c48be05fb994cc4818b5203a2f5ec81"
          ]
        },
        "id": "f27APH6H0e3W",
        "outputId": "4761e87f-9af8-4e0c-fe59-04d2e28c4482"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed65d42325ca4a7785436c0ad75d5f78",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1902 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "validation_dataset_arabic = tydiqa['arabic']['validation'].map(partial(get_validation_features, tk), batched=True, remove_columns=tydiqa['arabic']['train'].column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8ALzqcO028O"
      },
      "outputs": [],
      "source": [
        "val_arab_dl = DataLoader(validation_dataset_arabic, collate_fn=val_collate_fn, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ui53Zpi208ew",
        "outputId": "5c851cc6-d06e-450e-9c6b-6ceae5a6322b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62/62 [00:20<00:00,  3.01it/s]\n"
          ]
        }
      ],
      "source": [
        "logits_arabic = predict(arabic_model,val_arab_dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0fWWRj41Eqz",
        "outputId": "fe6bd59c-7410-4e10-a2a5-ab93892ba168"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1902/1902 [00:03<00:00, 479.25it/s]\n"
          ]
        }
      ],
      "source": [
        "predictions_arabic = post_process_predictions(tydiqa['arabic']['validation'], validation_dataset_arabic, logits_arabic)\n",
        "formatted_predictions_arabic = [{'id': k, 'prediction_text': v, 'no_answer_probability': 0.5} for k,v in predictions_arabic.items()]\n",
        "references_arabic = [{'answers': example['answers'], 'id' : example['id']} for example in tydiqa['arabic']['validation']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkTRyAha1bSc",
        "outputId": "51e05c09-3184-40ab-cf7c-1ec4f4b71126"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'exact': 31.70347003154574,\n",
              " 'f1': 40.40158676404807,\n",
              " 'total': 1902,\n",
              " 'HasAns_exact': 31.70347003154574,\n",
              " 'HasAns_f1': 40.40158676404807,\n",
              " 'HasAns_total': 1902,\n",
              " 'best_exact': 31.70347003154574,\n",
              " 'best_exact_thresh': 0.5,\n",
              " 'best_f1': 40.40158676404807,\n",
              " 'best_f1_thresh': 0.5}"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compute_squad.compute(predictions=formatted_predictions_arabic, references = references_arabic)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWRcj_r9gHQp"
      },
      "source": [
        "## Language specific transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPm6-hXvKJo_"
      },
      "source": [
        "### Indonesian: \"cahya/bert-base-indonesian-522M\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44DmW-FJ-QZ8"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "\n",
        "enforce_reproducibility()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "DgichRqZql_b"
      },
      "outputs": [],
      "source": [
        "#MODEL_NAME = \"cahya/bert-base-indonesian-522M\"\n",
        "#MODEL_NAME = \"indobenchmark/indobert-base-p2\"\n",
        "MODEL_NAME =  \"indolem/indobert-base-uncased\"\n",
        "tk = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "06bfaeabe8054abf8d295ede7d75b695",
            "7fb2777871194bb18c1606742ee6b6be",
            "6e62a96113144dc290ab1d2513db987a",
            "5c245d2bd0c9412ca5bed447c11c1176",
            "02d27da3a68c43c6bd5fe344bb174c57",
            "a1939fdccdda4217937689ec9d8c44be",
            "30d61cbaed0949a9bfe39e4f9da41814",
            "47d608838b724e00aa0465be1aa7e669",
            "d6030268e1744c6d9e24d2f374438e1d",
            "adedf103336949e9a215db3baa2b4072",
            "e8093fed4b9244cd8178c1d4b2fb3d49"
          ]
        },
        "id": "IEQVxjLjs8Ur",
        "outputId": "d8597197-e327-40d7-9aff-2ce38a76a700"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06bfaeabe8054abf8d295ede7d75b695",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/11394 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenized_dataset_indonesian = tydiqa['indonesian']['train'].map(partial(get_train_features, tk), batched=True, remove_columns=tydiqa['indonesian']['train'].column_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "WWBiQ1zYs8jL"
      },
      "outputs": [],
      "source": [
        "#samples_indonesian = random.sample(list(range(len(tokenized_dataset_indonesian))), 4000)\n",
        "#tokenized_dataset_indonesian = tokenized_dataset_indonesian.select(samples_indonesian)\n",
        "train_dl_indonesian = DataLoader(tokenized_dataset_indonesian, collate_fn=collate_fn, shuffle=True, batch_size=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "130248adbe0c4a69bdefce75d6f7369c",
            "a73df07c9c394f79993244aea20bd1ba",
            "50d50f40dc6a4938af0612b229e216f0",
            "0c321ad71fc04e71838295efae87ce55",
            "f690915664b54e8daaddd2d7ed580367",
            "ddf35f0cb9f3430eb9bc30201c930e2c",
            "ca4c34f615494e9ebfcb5698434fb2bb",
            "82cc328cd5df48ac9537139996712c08",
            "23679bbbfed64a25933243070cdfb393",
            "613698e2092a4c5ba48f34635bc6a783",
            "d27d00297e784eb9b6d4e30ee9d96130"
          ]
        },
        "id": "DR1XLr_bs8p2",
        "outputId": "bb81ef42-43b4-4de6-d169-3e5d2afd50c7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "130248adbe0c4a69bdefce75d6f7369c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/445M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at indolem/indobert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model_indonesian = AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "UFXdj_y4s8xU"
      },
      "outputs": [],
      "source": [
        "# Create the optimizer\n",
        "lr=2e-5\n",
        "n_epochs = 5\n",
        "weight_decay = 0.01\n",
        "warmup_steps = 200\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model_indonesian.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "      'weight_decay': weight_decay},\n",
        "    {'params': [p for n, p in model_indonesian.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=lr)\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    warmup_steps,\n",
        "    n_epochs * len(train_dl_indonesian)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQQiwypmtAXQ",
        "outputId": "e150e52a-d53d-478d-9ee0-14d850732a9b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2887/2887 [03:15<00:00, 14.76it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2887/2887 [03:09<00:00, 15.23it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2887/2887 [03:08<00:00, 15.29it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2887/2887 [03:09<00:00, 15.20it/s]\n"
          ]
        }
      ],
      "source": [
        "losses = train(\n",
        "    model_indonesian,\n",
        "    train_dl_indonesian,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    n_epochs,\n",
        "    device\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "63257b2b88004ca1b065d8df4d234631",
            "cb5624a437844545aa6794f6c2dbcd07",
            "f322facf84be4077917e16e1c42da931",
            "79dbf13ddab04ccabccc9eae39a81308",
            "9d65fe4b8d2846c494e6e3969d540c92",
            "642feb00c56244d7b2c160687811861b",
            "6b3bd2663cb042b5aa5355b3ddb5a149",
            "6a10801b0c914d9786b69a4e5cccdc7d",
            "0d7a95a0190d43cfb6afb0fdeb127e3e",
            "1cdad9bb27524af2b55ebdda9cc19f6b",
            "5962d8f92e2e49ffa138a93e1a7e0027"
          ]
        },
        "id": "MdVClaZatAco",
        "outputId": "fac4e1ce-570e-4ac0-a618-0a7546d44b74"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63257b2b88004ca1b065d8df4d234631",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1191 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:09<00:00,  4.04it/s]\n"
          ]
        }
      ],
      "source": [
        "validation_dataset_indonesian = tydiqa['indonesian']['validation'].map(partial(get_validation_features, tk), batched=True, remove_columns=tydiqa['indonesian']['train'].column_names)\n",
        "\n",
        "val_dl_indonesian = DataLoader(validation_dataset_indonesian, collate_fn=val_collate_fn, batch_size=32)\n",
        "logits_indonesian = predict(model_indonesian, val_dl_indonesian)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dULXSlSEtAiY",
        "outputId": "742f8c6b-f061-4d63-8d2a-181140207f41"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1191/1191 [00:02<00:00, 413.60it/s]\n"
          ]
        }
      ],
      "source": [
        "predictions_indonesian = post_process_predictions(tydiqa['indonesian']['validation'], validation_dataset_indonesian, logits_indonesian)\n",
        "formatted_predictions_indonesian = [{'id': k, 'prediction_text': v, 'no_answer_probability': 0.5} for k,v in predictions_indonesian.items()]\n",
        "references_indonesian = [{'answers': example['answers'], 'id' : example['id']} for example in tydiqa['indonesian']['validation']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZ_gGtCAtAoM",
        "outputId": "1f48f631-bc44-491b-b8ef-c294966f4a8f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'exact': 44.24853064651553,\n",
              " 'f1': 49.60680053655968,\n",
              " 'total': 1191,\n",
              " 'HasAns_exact': 44.24853064651553,\n",
              " 'HasAns_f1': 49.60680053655968,\n",
              " 'HasAns_total': 1191,\n",
              " 'best_exact': 44.24853064651553,\n",
              " 'best_exact_thresh': 0.5,\n",
              " 'best_f1': 49.60680053655968,\n",
              " 'best_f1_thresh': 0.5}"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compute_squad.compute(predictions=formatted_predictions_indonesian, references = references_indonesian)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZji-6pjtjm2"
      },
      "source": [
        "### Bengali: \"csebuetnlp/banglishbert\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AeG_TIw9-Rsj"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "\n",
        "enforce_reproducibility()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "IGeD6NfNtu6i"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"csebuetnlp/banglishbert\"\n",
        "tk = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "ObtpKtoWtvCs"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset_bengali = tydiqa['bengali']['train'].map(partial(get_train_features, tk), batched=True, remove_columns=tydiqa['bengali']['train'].column_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4_Hu8KdtvIf",
        "outputId": "8035552d-3262-430c-ecbe-ae16bb8147d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ElectraForQuestionAnswering were not initialized from the model checkpoint at csebuetnlp/banglishbert and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "bengali_model = AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "jwvK5q3NtvU4"
      },
      "outputs": [],
      "source": [
        "#samples_bengali = random.sample(list(range(len(tokenized_dataset_bengali))), 4000)\n",
        "#tokenized_dataset_bengali = tokenized_dataset_bengali.select(samples_bengali)\n",
        "train_dl_bengali = DataLoader(tokenized_dataset_bengali, collate_fn=collate_fn, shuffle=True, batch_size=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_VgwTNXtvcZ",
        "outputId": "8e839f9c-07bd-4b0f-dca8-5ee611b62dcc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1220/1220 [01:36<00:00, 12.70it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1220/1220 [01:39<00:00, 12.25it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1220/1220 [01:31<00:00, 13.36it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1220/1220 [01:33<00:00, 13.09it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1220/1220 [01:31<00:00, 13.27it/s]\n"
          ]
        }
      ],
      "source": [
        "# Create the optimizer\n",
        "lr=2e-5\n",
        "n_epochs = 5\n",
        "weight_decay = 0.01\n",
        "warmup_steps = 200\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in bengali_model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "      'weight_decay': weight_decay},\n",
        "    {'params': [p for n, p in bengali_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "# optimizer = Adam(optimizer_grouped_parameters, lr=1e-3)\n",
        "# scheduler = None\n",
        "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=lr)\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    warmup_steps,\n",
        "    n_epochs * len(train_dl_bengali)\n",
        ")\n",
        "\n",
        "losses = train(\n",
        "    bengali_model,\n",
        "    train_dl_bengali,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    n_epochs,\n",
        "    device\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "yrH1-dmFt7cW"
      },
      "outputs": [],
      "source": [
        "validation_dataset_beng = tydiqa['bengali']['validation'].map(partial(get_validation_features, tk), batched=True, remove_columns=tydiqa['bengali']['train'].column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "mavjcYaFt7iZ"
      },
      "outputs": [],
      "source": [
        "val_beng_dl = DataLoader(validation_dataset_beng, collate_fn=val_collate_fn, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNL9VqNmt7pG",
        "outputId": "2e05c8b4-623b-4ae6-c27e-57c29e10a893"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.09it/s]\n"
          ]
        }
      ],
      "source": [
        "logits_beng = predict(bengali_model, val_beng_dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAywxAjMt7u-",
        "outputId": "9d16b57d-0111-467a-a830-49bc1497f21d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:00<00:00, 430.02it/s]\n"
          ]
        }
      ],
      "source": [
        "predictions_beng = post_process_predictions(tydiqa['bengali']['validation'], validation_dataset_beng, logits_beng)\n",
        "formatted_predictions_beng = [{'id': k, 'prediction_text': v, 'no_answer_probability': 0.5} for k,v in predictions_beng.items()]\n",
        "references_beng = [{'answers': example['answers'], 'id' : example['id']} for example in tydiqa['bengali']['validation']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bglSQ5uit72e",
        "outputId": "88c8b92f-fbba-4234-d680-d460f542123d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'exact': 33.482142857142854,\n",
              " 'f1': 38.35197540554684,\n",
              " 'total': 224,\n",
              " 'HasAns_exact': 33.482142857142854,\n",
              " 'HasAns_f1': 38.35197540554684,\n",
              " 'HasAns_total': 224,\n",
              " 'best_exact': 33.482142857142854,\n",
              " 'best_exact_thresh': 0.5,\n",
              " 'best_f1': 38.35197540554684,\n",
              " 'best_f1_thresh': 0.5}"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compute_squad.compute(predictions=formatted_predictions_beng, references = references_beng)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrEWFb00u_M1"
      },
      "source": [
        "### Arabic: \"aubmindlab/bert-base-arabertv02\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "qXQz26RR-TCp"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "\n",
        "enforce_reproducibility()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "EoiYV0DNu9gc"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"aubmindlab/bert-base-arabertv02\"\n",
        "tk = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "wnF5oTiNu9pw"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset_arabic = tydiqa['arabic']['train'].map(partial(get_train_features, tk), batched=True, remove_columns=tydiqa['arabic']['train'].column_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eyF-gStu93T",
        "outputId": "618e80b7-a8a7-40ce-f942-0edeb3ff82fc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "arabic_model = AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "vemv9NDDvI5y"
      },
      "outputs": [],
      "source": [
        "#samples = random.sample(list(range(len(tokenized_dataset_arabic))), 4000)\n",
        "#tokenized_dataset_arabic = tokenized_dataset_arabic.select(samples)\n",
        "train_dl_arabic = DataLoader(tokenized_dataset_arabic, collate_fn=collate_fn, shuffle=True, batch_size=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bL9NOQPFvI_E",
        "outputId": "8b4c626c-341b-4f48-fb8f-db5e4c4547ff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7529/7529 [09:09<00:00, 13.71it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7529/7529 [09:03<00:00, 13.84it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7529/7529 [09:04<00:00, 13.83it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7529/7529 [09:01<00:00, 13.91it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7529/7529 [09:03<00:00, 13.86it/s]\n"
          ]
        }
      ],
      "source": [
        "# Create the optimizer\n",
        "lr=2e-5\n",
        "n_epochs = 5\n",
        "weight_decay = 0.01\n",
        "warmup_steps = 200\n",
        "\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in arabic_model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "      'weight_decay': weight_decay},\n",
        "    {'params': [p for n, p in arabic_model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "# optimizer = Adam(optimizer_grouped_parameters, lr=1e-3)\n",
        "# scheduler = None\n",
        "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=lr)\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    warmup_steps,\n",
        "    n_epochs * len(train_dl_arabic)\n",
        ")\n",
        "\n",
        "losses = train(\n",
        "    arabic_model,\n",
        "    train_dl_arabic,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    n_epochs,\n",
        "    device\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "tbqnamzqvJD6"
      },
      "outputs": [],
      "source": [
        "validation_dataset_arabic = tydiqa['arabic']['validation'].map(partial(get_validation_features, tk), batched=True, remove_columns=tydiqa['arabic']['train'].column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMC9l2lovJH6",
        "outputId": "5873e11b-beca-4cc6-d9b5-16dc06ab2011"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:15<00:00,  3.82it/s]\n"
          ]
        }
      ],
      "source": [
        "val_arab_dl = DataLoader(validation_dataset_arabic, collate_fn=val_collate_fn, batch_size=32)\n",
        "logits_arabic = predict(arabic_model,val_arab_dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT3SuPAou-D-",
        "outputId": "d52d85a8-0694-4bed-ff28-4bf6fd090dc8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1902/1902 [00:05<00:00, 324.78it/s]\n"
          ]
        }
      ],
      "source": [
        "predictions_arabic = post_process_predictions(tydiqa['arabic']['validation'], validation_dataset_arabic, logits_arabic)\n",
        "formatted_predictions_arabic = [{'id': k, 'prediction_text': v, 'no_answer_probability': 0.5} for k,v in predictions_arabic.items()]\n",
        "references_arabic = [{'answers': example['answers'], 'id' : example['id']} for example in tydiqa['arabic']['validation']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QjAfIdsu-IF",
        "outputId": "0f5797aa-dc6f-469a-a118-ea3114fda7a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'exact': 36.487907465825444,\n",
              " 'f1': 45.14689457093472,\n",
              " 'total': 1902,\n",
              " 'HasAns_exact': 36.487907465825444,\n",
              " 'HasAns_f1': 45.14689457093472,\n",
              " 'HasAns_total': 1902,\n",
              " 'best_exact': 36.487907465825444,\n",
              " 'best_exact_thresh': 0.5,\n",
              " 'best_f1': 45.14689457093472,\n",
              " 'best_f1_thresh': 0.5}"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "compute_squad.compute(predictions=formatted_predictions_arabic, references = references_arabic)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# IOB model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "df = load_dataset(\"copenlu/answerable_tydiqa\")\n",
        "\n",
        "language = \"bengali\"\n",
        "df_train = df[\"train\"].filter(lambda x: x[\"language\"] == language)\n",
        "#df_train = df_train.train_test_split(test_size = 0.02)['test']\n",
        "df_val = df[\"validation\"].filter(lambda x: x[\"language\"] == language)\n",
        "#df_val = df_val.train_test_split(test_size = 0.1)['test']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defining new columns to tokenize only the text we need"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def format(dataset):\n",
        "    result = {}\n",
        "    #Marking start of the sentence and where the question and plaintext separates\n",
        "    result['sentence'] = '[CLS] ' + dataset['question_text'] + ' [SEP] ' + dataset['document_plaintext']\n",
        "    #Where the answer starts in the document_plaintext\n",
        "    answer_start = dataset['annotations']['answer_start'][0] + len(dataset['question_text']) + len(\"[CLS] \") + len(\" [SEP] \")\n",
        "    result['answer_start'] = answer_start\n",
        "    #WHere the answer ends in the document_plaintext\n",
        "    result['answer_end'] = answer_start + len(dataset['annotations']['answer_text'][0])\n",
        "    #Where the answer starts in the document_plaintext\n",
        "    #WHere the answer ends in the document_plaintext\n",
        "    return result\n",
        "\n",
        "\n",
        "def iob(ans_ids, tokens):\n",
        "    result = []\n",
        "    for answerID, token_word in enumerate(tokens):\n",
        "        if token_word in ['[CLS]', '[SEP]']:\n",
        "            result.append(-100)\n",
        "        elif len(ans_ids) > 0 and answerID == ans_ids[0]:\n",
        "            result.append(1)\n",
        "        elif answerID in ans_ids:\n",
        "            result.append(2)\n",
        "        else:\n",
        "            result.append(0)\n",
        "    return result\n",
        "\n",
        "\n",
        "def token_iob_labels(examples):\n",
        "    sentence_tokens = tokenizer(examples[\"sentence\"], truncation=True)\n",
        "    answer_start = examples['answer_start']\n",
        "    answer_end = examples['answer_end']\n",
        "    sentence_token_id = []\n",
        "    for id in range(len(sentence_tokens.tokens())):\n",
        "        sentencespan = sentence_tokens.token_to_chars(batch_or_token_index=id)\n",
        "        if sentencespan is not None:\n",
        "            (elem1, _) = sentencespan\n",
        "            if elem1 > answer_end:\n",
        "                break\n",
        "            elif elem1 >= answer_start:\n",
        "                sentence_token_id.append(id)\n",
        "    sentence_tokens[\"labels\"] = iob(sentence_token_id, sentence_tokens.tokens())\n",
        "    sentence_tokens['text_tokens'] = sentence_tokens.tokens()\n",
        "    return sentence_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the multilingual bert model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\kaspe\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, DataCollatorForTokenClassification, AdamW, get_scheduler\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = \"bert-base-multilingual-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "model_auto = AutoModelForTokenClassification.from_pretrained(model, num_labels=3)\n",
        "model_auto.to(device)\n",
        "collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
        "optimizer = AdamW(model_auto.parameters(), lr=2e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d9e308b9ef6481ca314979f3195a649",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/4779 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab5bb870111f4121ba089f2f76b2a769",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/4779 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c042b6dca224349b7b71d571d2bd03f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/224 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "576aceb7a5584b40821669223c31b013",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/224 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenized_datasets_train = df_train.map(format).map(\n",
        "    token_iob_labels\n",
        ")\n",
        "tokenized_datasets_val = df_val.map(format).map(\n",
        "    token_iob_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extracting the columns we need (input ids, attention mask, iob labels and token type id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_dataloader = DataLoader(\n",
        "    tokenized_datasets_train.remove_columns(['question_text', 'document_title', 'language', 'annotations', 'document_plaintext', 'document_url', 'sentence', 'answer_start', 'answer_end', 'text_tokens']), shuffle=True, batch_size=4, collate_fn=collator\n",
        ")\n",
        "eval_dataloader = DataLoader(\n",
        "    tokenized_datasets_val.remove_columns(['question_text', 'document_title', 'language', 'annotations', 'document_plaintext', 'document_url', 'sentence', 'answer_start', 'answer_end', 'text_tokens']), batch_size=4, collate_fn=collator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs = 1\n",
        "num_class = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for batch in train_dataloader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        token_type_ids = batch['token_type_ids'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model_auto(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, labels=labels)\n",
        "\n",
        "        logits = outputs.get(\"logits\").to(device)\n",
        "\n",
        "        loss = outputs.loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [00:06<00:00, 35.37it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "y_true_flat = []\n",
        "y_pred_flat = []\n",
        "y_true = []\n",
        "y_pred = []\n",
        "for val_data in tqdm(tokenized_datasets_val):\n",
        "  input_ids = torch.LongTensor([val_data['input_ids']]).to(device)\n",
        "  attention_mask = torch.LongTensor([val_data['attention_mask']]).to(device)\n",
        "  output = model_auto(input_ids=input_ids, attention_mask=attention_mask)\n",
        "  _, predictions = torch.max(output.logits, 2)\n",
        "  y_true.append(val_data['labels'])\n",
        "  y_true_flat.extend(val_data['labels'])\n",
        "  y_pred.append(predictions[0].detach().cpu().numpy())\n",
        "  y_pred_flat.extend(predictions[0].detach().cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_exact_match(predicted, true, replacement_value=0):\n",
        "    assert len(predicted) == len(true), \"Length of predicted and true labels must match\"\n",
        "    em = 0\n",
        "    total = len(predicted)\n",
        "\n",
        "    predicted = [[replacement_value if x == -100 else x for x in seq] for seq in predicted]\n",
        "    true = [[replacement_value if x == -100 else x for x in seq] for seq in true]\n",
        "\n",
        "    for pred_seq, true_seq in zip(predicted, true):\n",
        "        if np.array_equal(pred_seq, true_seq):\n",
        "            em += 1\n",
        "\n",
        "    em_score = em / total\n",
        "    return em_score\n",
        "\n",
        "em_score_bengali = compute_exact_match(y_pred, y_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BENGALI\n",
            "*********\n",
            "F1:  0.49739710538218\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "precision_bengali, recall_bengali, f1_bengali, _ = precision_recall_fscore_support(y_true_flat, y_pred_flat, average='macro', zero_division=1)\n",
        "\n",
        "print(\"BENGALI\")\n",
        "print(\"*********\")\n",
        "print(\"F1: \", f1_bengali)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ARABIC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\kaspe\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c707ad2b534443c4837141474cb7517f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/29598 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "150bedcdc2e645a9897d0b2c067fe4fd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/29598 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48e13d0e97d84dcfb0672a1514636e7f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1902 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8856f561962e4f6daf40dab8b9c19cc2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1902 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1902/1902 [00:52<00:00, 36.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ARABIC\n",
            "*********\n",
            "F1:  0.5839945969542365\n"
          ]
        }
      ],
      "source": [
        "language = \"arabic\"\n",
        "df_train = df[\"train\"].filter(lambda x: x[\"language\"] == language)\n",
        "#df_train = df_train.train_test_split(test_size = 0.1)['test']\n",
        "df_val = df[\"validation\"].filter(lambda x: x[\"language\"] == language)\n",
        "#df_val = df_val.train_test_split(test_size = 0.1)['test']\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = \"bert-base-multilingual-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "model_auto = AutoModelForTokenClassification.from_pretrained(model, num_labels=3)\n",
        "model_auto.to(device)\n",
        "collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
        "optimizer = AdamW(model_auto.parameters(), lr=2e-5)\n",
        "\n",
        "\n",
        "tokenized_datasets = df_train.map(format).map(\n",
        "    token_iob_labels\n",
        ")\n",
        "tokenized_datasets_val = df_val.map(format).map(\n",
        "    token_iob_labels\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    tokenized_datasets.remove_columns(['question_text', 'document_title', 'language', 'annotations', 'document_plaintext', 'document_url', 'sentence', 'answer_start', 'answer_end', 'text_tokens']), shuffle=True, batch_size=8, collate_fn=collator\n",
        ")\n",
        "eval_dataloader = DataLoader(\n",
        "    tokenized_datasets_val.remove_columns(['question_text', 'document_title', 'language', 'annotations', 'document_plaintext', 'document_url', 'sentence', 'answer_start', 'answer_end', 'text_tokens']), batch_size=8, collate_fn=collator\n",
        ")\n",
        "\n",
        "epochs = 1\n",
        "num_class = 3\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for batch in train_dataloader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        token_type_ids = batch['token_type_ids'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model_auto(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, labels=labels)\n",
        "\n",
        "        logits = outputs.get(\"logits\").to(device)\n",
        "\n",
        "        loss = outputs.loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "y_true_flat_arab = []\n",
        "y_pred_flat_arab = []\n",
        "y_pred_arab = []\n",
        "y_true_arab = []\n",
        "for val_data in tqdm(tokenized_datasets_val):\n",
        "  input_ids = torch.LongTensor([val_data['input_ids']]).to(device)\n",
        "  attention_mask = torch.LongTensor([val_data['attention_mask']]).to(device)\n",
        "  output = model_auto(input_ids=input_ids, attention_mask=attention_mask)\n",
        "  _, predictions = torch.max(output.logits, 2)\n",
        "  y_true_arab.append(val_data['labels'])\n",
        "  y_true_flat_arab.extend(val_data['labels'])\n",
        "  y_pred_arab.append(predictions[0].detach().cpu().numpy())\n",
        "  y_pred_flat_arab.extend(predictions[0].detach().cpu().numpy())\n",
        "\n",
        "\n",
        "em_score_arab = compute_exact_match(y_pred_arab, y_true_arab)\n",
        "precision_arab, recall_arab, f1_arab, _ = precision_recall_fscore_support(y_true_flat_arab, y_pred_flat_arab, average='macro', zero_division=1)\n",
        "print(\"ARABIC\")\n",
        "print(\"*********\")\n",
        "print(\"F1: \", f1_arab)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "INDONESIAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "c:\\Users\\kaspe\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14212cb245344b5c9bba799aca9bc2a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/11394 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c68cfc969cd6431c9bc994d609e24416",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/11394 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e39c5ef7ee0f46be84440c91deeacd29",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1191 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a156ac37b0644161b2cfb68cafdc43b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1191 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1191/1191 [00:35<00:00, 33.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INDONESIAN\n",
            "*********\n",
            "F1:  0.5463268754111743\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "language = \"indonesian\"\n",
        "df_train = df[\"train\"].filter(lambda x: x[\"language\"] == language)\n",
        "#df_train = df_train.train_test_split(test_size = 0.1)['test']\n",
        "df_val = df[\"validation\"].filter(lambda x: x[\"language\"] == language)\n",
        "#df_val = df_val.train_test_split(test_size = 0.1)['test']\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = \"bert-base-multilingual-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "model_auto = AutoModelForTokenClassification.from_pretrained(model, num_labels=3)\n",
        "model_auto.to(device)\n",
        "collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
        "optimizer = AdamW(model_auto.parameters(), lr=2e-5)\n",
        "\n",
        "\n",
        "tokenized_datasets = df_train.map(format).map(\n",
        "    token_iob_labels\n",
        ")\n",
        "tokenized_datasets_val = df_val.map(format).map(\n",
        "    token_iob_labels\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    tokenized_datasets.remove_columns(['question_text', 'document_title', 'language', 'annotations', 'document_plaintext', 'document_url', 'sentence', 'answer_start', 'answer_end', 'text_tokens']), shuffle=True, batch_size=8, collate_fn=collator\n",
        ")\n",
        "eval_dataloader = DataLoader(\n",
        "    tokenized_datasets_val.remove_columns(['question_text', 'document_title', 'language', 'annotations', 'document_plaintext', 'document_url', 'sentence', 'answer_start', 'answer_end', 'text_tokens']), batch_size=8, collate_fn=collator\n",
        ")\n",
        "\n",
        "epochs = 1\n",
        "num_class = 3\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for batch in train_dataloader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        token_type_ids = batch['token_type_ids'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model_auto(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, labels=labels)\n",
        "\n",
        "        logits = outputs.get(\"logits\").to(device)\n",
        "\n",
        "        loss = outputs.loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "y_true_flat_indo = []\n",
        "y_pred_flat_indo = []\n",
        "y_true_indo = []\n",
        "y_pred_indo = []\n",
        "for val_data in tqdm(tokenized_datasets_val):\n",
        "  input_ids = torch.LongTensor([val_data['input_ids']]).to(device)\n",
        "  attention_mask = torch.LongTensor([val_data['attention_mask']]).to(device)\n",
        "  output = model_auto(input_ids=input_ids, attention_mask=attention_mask)\n",
        "  _, predictions = torch.max(output.logits, 2)\n",
        "  y_true_indo.append(val_data['labels'])\n",
        "  y_true_flat_indo.extend(val_data['labels'])\n",
        "  y_pred_indo.append(predictions[0].detach().cpu().numpy())\n",
        "  y_pred_flat_indo.extend(predictions[0].detach().cpu().numpy())\n",
        "\n",
        "\n",
        "em_score_indo = compute_exact_match(y_pred_indo, y_true_indo)\n",
        "precision_indo, recall_indo, f1_indo, _ = precision_recall_fscore_support(y_true_flat_indo, y_pred_flat_indo, average='macro', zero_division=1)\n",
        "\n",
        "print(\"INDONESIAN\")\n",
        "print(\"*********\")\n",
        "print(\"F1: \", f1_indo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "RESULT TOGETHER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "BENGALI\n",
            "*********\n",
            "EM Score: 0.5223214285714286\n",
            "f1 Score: 0.49739710538218\n",
            "precision Score: 0.7967041697707318\n",
            "\n",
            "\n",
            "ARABIC\n",
            "*********\n",
            "EM Score: 0.6393270241850684\n",
            "f1 Score: 0.5839945969542365\n",
            "precision Score: 0.8724910411972784\n",
            "\n",
            "\n",
            "INDONESIAN\n",
            "*********\n",
            "EM Score: 0.5852225020990764\n",
            "f1 Score: 0.5463268754111743\n",
            "precision Score: 0.852818885666527\n"
          ]
        }
      ],
      "source": [
        "print()\n",
        "print(\"BENGALI\")\n",
        "print(\"*********\")\n",
        "print(f\"EM Score: {em_score_bengali}\")\n",
        "print(f\"f1 Score: {f1_bengali}\")\n",
        "print(f\"precision Score: {precision_bengali}\")\n",
        "print()\n",
        "print()\n",
        "print(\"ARABIC\")\n",
        "print(\"*********\")\n",
        "print(f\"EM Score: {em_score_arab}\")\n",
        "print(f\"f1 Score: {f1_arab}\")\n",
        "print(f\"precision Score: {precision_arab}\")\n",
        "print()\n",
        "print()\n",
        "print(\"INDONESIAN\")\n",
        "print(\"*********\")\n",
        "print(f\"EM Score: {em_score_indo}\")\n",
        "print(f\"f1 Score: {f1_indo}\")\n",
        "print(f\"precision Score: {precision_indo}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02d27da3a68c43c6bd5fe344bb174c57": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03490e623a7445e29836b8c045286ce5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06bfaeabe8054abf8d295ede7d75b695": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7fb2777871194bb18c1606742ee6b6be",
              "IPY_MODEL_6e62a96113144dc290ab1d2513db987a",
              "IPY_MODEL_5c245d2bd0c9412ca5bed447c11c1176"
            ],
            "layout": "IPY_MODEL_02d27da3a68c43c6bd5fe344bb174c57"
          }
        },
        "0c321ad71fc04e71838295efae87ce55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_613698e2092a4c5ba48f34635bc6a783",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d27d00297e784eb9b6d4e30ee9d96130",
            "value": " 445M/445M [00:22&lt;00:00, 21.7MB/s]"
          }
        },
        "0d7a95a0190d43cfb6afb0fdeb127e3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "130248adbe0c4a69bdefce75d6f7369c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a73df07c9c394f79993244aea20bd1ba",
              "IPY_MODEL_50d50f40dc6a4938af0612b229e216f0",
              "IPY_MODEL_0c321ad71fc04e71838295efae87ce55"
            ],
            "layout": "IPY_MODEL_f690915664b54e8daaddd2d7ed580367"
          }
        },
        "13a71ed997494a8296aa11f42d9e1589": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f2666fd7a8849c4a5e91cd68a7129cf",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_72eb2b422b37492381bacffeec97b1ee",
            "value": "Map: 100%"
          }
        },
        "19ce64d01e494d6b8a9579bdb2342bb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1cdad9bb27524af2b55ebdda9cc19f6b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e683f1484ac4be38cba81c2c4e23b6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b8674dc5af04e30bdc5a435ead04a8c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c9702701430b4ef699d4ff58f4c8747f",
            "value": " 224/224 [00:00&lt;00:00, 718.68 examples/s]"
          }
        },
        "21ca25d58f544ba69b9b497e23cd36f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40e9bdb37e4440d98b7f3ff3cb8a158b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3be1847ede7444a490bdde78ab67e258",
            "value": "Map: 100%"
          }
        },
        "23679bbbfed64a25933243070cdfb393": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30d61cbaed0949a9bfe39e4f9da41814": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "326010bfd86a42c78cb774de6c343d91": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3be1847ede7444a490bdde78ab67e258": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40e9bdb37e4440d98b7f3ff3cb8a158b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47d608838b724e00aa0465be1aa7e669": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a9f5272d338449c8b358ed9789c35ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b8674dc5af04e30bdc5a435ead04a8c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4deeaaa2a58845c795fdd5b536f8f9ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50d50f40dc6a4938af0612b229e216f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82cc328cd5df48ac9537139996712c08",
            "max": 444780374,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23679bbbfed64a25933243070cdfb393",
            "value": 444780374
          }
        },
        "5962d8f92e2e49ffa138a93e1a7e0027": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bf79c9c59cf46fca42266812ac3baf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7967180a5224349ac7b1912adf60fd1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7e5a1047764548d18c8c2bc9e42100e2",
            "value": "Map: 100%"
          }
        },
        "5c245d2bd0c9412ca5bed447c11c1176": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adedf103336949e9a215db3baa2b4072",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e8093fed4b9244cd8178c1d4b2fb3d49",
            "value": " 11394/11394 [00:10&lt;00:00, 1361.02 examples/s]"
          }
        },
        "613698e2092a4c5ba48f34635bc6a783": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63257b2b88004ca1b065d8df4d234631": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb5624a437844545aa6794f6c2dbcd07",
              "IPY_MODEL_f322facf84be4077917e16e1c42da931",
              "IPY_MODEL_79dbf13ddab04ccabccc9eae39a81308"
            ],
            "layout": "IPY_MODEL_9d65fe4b8d2846c494e6e3969d540c92"
          }
        },
        "642feb00c56244d7b2c160687811861b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65aef3f0c7e24db39ccd6a22536961fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03490e623a7445e29836b8c045286ce5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8c48be05fb994cc4818b5203a2f5ec81",
            "value": " 1902/1902 [00:02&lt;00:00, 670.73 examples/s]"
          }
        },
        "691663e8d179451f9c6f748668ac6214": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b555d9a5919431f961e5e37f49ee9e8",
            "max": 1191,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4deeaaa2a58845c795fdd5b536f8f9ca",
            "value": 1191
          }
        },
        "6a10801b0c914d9786b69a4e5cccdc7d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b3bd2663cb042b5aa5355b3ddb5a149": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e62a96113144dc290ab1d2513db987a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47d608838b724e00aa0465be1aa7e669",
            "max": 11394,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6030268e1744c6d9e24d2f374438e1d",
            "value": 11394
          }
        },
        "6f2666fd7a8849c4a5e91cd68a7129cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72eb2b422b37492381bacffeec97b1ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79dbf13ddab04ccabccc9eae39a81308": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cdad9bb27524af2b55ebdda9cc19f6b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5962d8f92e2e49ffa138a93e1a7e0027",
            "value": " 1191/1191 [00:01&lt;00:00, 1074.81 examples/s]"
          }
        },
        "7e5a1047764548d18c8c2bc9e42100e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ed960596ef04e4b90989c440d9971f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86a9059734a44d1bad58df3a6e829965",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4a9f5272d338449c8b358ed9789c35ed",
            "value": " 1191/1191 [00:01&lt;00:00, 661.47 examples/s]"
          }
        },
        "7fb2777871194bb18c1606742ee6b6be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1939fdccdda4217937689ec9d8c44be",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_30d61cbaed0949a9bfe39e4f9da41814",
            "value": "Map: 100%"
          }
        },
        "82cc328cd5df48ac9537139996712c08": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86a9059734a44d1bad58df3a6e829965": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c48be05fb994cc4818b5203a2f5ec81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97b9f3adfd734d26899c019fd726fc40": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b555d9a5919431f961e5e37f49ee9e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d65fe4b8d2846c494e6e3969d540c92": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1939fdccdda4217937689ec9d8c44be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a73df07c9c394f79993244aea20bd1ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddf35f0cb9f3430eb9bc30201c930e2c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ca4c34f615494e9ebfcb5698434fb2bb",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "a9ae279af8964aabad8f410af59ae1c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5bf79c9c59cf46fca42266812ac3baf6",
              "IPY_MODEL_d49e4b566fb6492aba84077af03878c0",
              "IPY_MODEL_1e683f1484ac4be38cba81c2c4e23b6f"
            ],
            "layout": "IPY_MODEL_e089df67654149bba79661a8c285f7c6"
          }
        },
        "adedf103336949e9a215db3baa2b4072": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7967180a5224349ac7b1912adf60fd1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c39528ec1f854f63934a2768149ce72b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97b9f3adfd734d26899c019fd726fc40",
            "max": 1902,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19ce64d01e494d6b8a9579bdb2342bb2",
            "value": 1902
          }
        },
        "c423c8bfaf5f42ddaa11c6f4cbc47771": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c9702701430b4ef699d4ff58f4c8747f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca4c34f615494e9ebfcb5698434fb2bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb5624a437844545aa6794f6c2dbcd07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_642feb00c56244d7b2c160687811861b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6b3bd2663cb042b5aa5355b3ddb5a149",
            "value": "Map: 100%"
          }
        },
        "d27d00297e784eb9b6d4e30ee9d96130": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d49e4b566fb6492aba84077af03878c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_326010bfd86a42c78cb774de6c343d91",
            "max": 224,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c423c8bfaf5f42ddaa11c6f4cbc47771",
            "value": 224
          }
        },
        "d6030268e1744c6d9e24d2f374438e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d73c44e9546347cbb514e277bc1b4a2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21ca25d58f544ba69b9b497e23cd36f6",
              "IPY_MODEL_691663e8d179451f9c6f748668ac6214",
              "IPY_MODEL_7ed960596ef04e4b90989c440d9971f1"
            ],
            "layout": "IPY_MODEL_f94aec55f65e47969b595f8b59e79d20"
          }
        },
        "ddf35f0cb9f3430eb9bc30201c930e2c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e089df67654149bba79661a8c285f7c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8093fed4b9244cd8178c1d4b2fb3d49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed65d42325ca4a7785436c0ad75d5f78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_13a71ed997494a8296aa11f42d9e1589",
              "IPY_MODEL_c39528ec1f854f63934a2768149ce72b",
              "IPY_MODEL_65aef3f0c7e24db39ccd6a22536961fb"
            ],
            "layout": "IPY_MODEL_eee0e5e47ce6417eaf40144976ad27b0"
          }
        },
        "eee0e5e47ce6417eaf40144976ad27b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f322facf84be4077917e16e1c42da931": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a10801b0c914d9786b69a4e5cccdc7d",
            "max": 1191,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d7a95a0190d43cfb6afb0fdeb127e3e",
            "value": 1191
          }
        },
        "f690915664b54e8daaddd2d7ed580367": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f94aec55f65e47969b595f8b59e79d20": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
